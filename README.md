# Oracle to Snowflake Data Pipeline

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-2.5+-red.svg)](https://airflow.apache.org/)

Um pipeline robusto e escal√°vel para extrair dados de m√∫ltiplos schemas Oracle RDS e carregar no Snowflake usando AWS MWAA (Managed Apache Airflow).

## üöÄ Caracter√≠sticas Principais

- **Extra√ß√£o Incremental Inteligente**: Detecta automaticamente colunas de timestamp para extra√ß√µes incrementais
- **Alta Performance**: Utiliza formato Parquet e staging em S3 para otimizar cargas
- **Monitoramento Completo**: M√©tricas CloudWatch, alertas Slack/email e valida√ß√£o de qualidade
- **Toler√¢ncia a Falhas**: Retry logic, pools de conex√£o e recovery autom√°tico
- **Escalabilidade**: Processamento paralelo por schema com controle de recursos

## üèóÔ∏è Arquitetura

```
Oracle RDS ‚Üí Airflow (MWAA) ‚Üí S3 (Staging) ‚Üí Snowflake
    ‚Üì              ‚Üì              ‚Üì            ‚Üì
Schemas/Tables ‚Üí Extraction ‚Üí Parquet Files ‚Üí Data Warehouse
```

### Componentes

- **Oracle RDS**: Banco de dados fonte com m√∫ltiplos schemas
- **AWS MWAA**: Orquestra√ß√£o via Apache Airflow gerenciado
- **Amazon S3**: Staging area para arquivos Parquet
- **Snowflake**: Data warehouse de destino
- **CloudWatch**: Monitoramento e alertas

## üìã Pr√©-requisitos

### Infraestrutura
- [ ] AWS Account com MWAA configurado
- [ ] Oracle RDS instance acess√≠vel
- [ ] Snowflake account ativo
- [ ] S3 bucket para staging
- [ ] IAM roles com permiss√µes adequadas

### Credenciais
- [ ] Usu√°rio Oracle com SELECT privileges
- [ ] Usu√°rio Snowflake com CREATE privileges
- [ ] AWS credentials para MWAA

## üõ†Ô∏è Instala√ß√£o

### 1. Clone o Reposit√≥rio
```bash
git clone https://github.com/seu-usuario/oracle-snowflake-pipeline.git
cd oracle-snowflake-pipeline
```

### 2. Configure o Ambiente
```bash
# Tornar script execut√°vel
chmod +x deployment/deploy_pipeline.sh

# Editar configura√ß√µes
cp .env.example .env
vim .env
```

### 3. Deploy Automatizado
```bash
./deployment/deploy_pipeline.sh
```

## ‚öôÔ∏è Configura√ß√£o

### Conex√µes Airflow

#### Oracle Connection
```json
{
  "conn_id": "oracle_conn",
  "conn_type": "oracle",
  "host": "your-oracle-endpoint.amazonaws.com",
  "port": 1521,
  "schema": "ORCL",
  "login": "your_user",
  "password": "your_password"
}
```

#### Snowflake Connection
```json
{
  "conn_id": "snowflake_conn",
  "conn_type": "snowflake",
  "host": "your-account.snowflakecomputing.com",
  "login": "your_user",
  "password": "your_password",
  "extra": {
    "account": "your_account",
    "warehouse": "COMPUTE_WH",
    "database": "ANALYTICS_DB"
  }
}
```

### Configura√ß√£o de Schemas/Tabelas

Edite `dags/oracle_to_snowflake_dag.py`:
```python
SCHEMAS_CONFIG = {
    'SCHEMA1': ['TABLE1', 'TABLE2', 'TABLE3'],
    'SCHEMA2': ['TABLE4', 'TABLE5'],
    'SCHEMA3': ['TABLE6', 'TABLE7', 'TABLE8']
}
```

## üöÄ Uso

### Execu√ß√£o Manual
1. Acesse Airflow Web UI
2. Ative o DAG `oracle_to_snowflake_pipeline`
3. Trigger manual execution

### Execu√ß√£o Programada
```python
# Configura√ß√£o no DAG
schedule_interval='0 2 * * *'  # Di√°rio √†s 2h AM
```

### Testes
```bash
# Executar testes unit√°rios
python -m pytest tests/

# Executar DAG de testes no Airflow
# Trigger: oracle_snowflake_tests
```

## üìä Monitoramento

### M√©tricas CloudWatch
- Pipeline execution time
- Data volume processed
- Success/failure rates
- Resource utilization

### Alertas
- **Email**: Configurado via SNS
- **Slack**: Webhook notifications
- **CloudWatch Alarms**: Threshold-based alerts

### Logs
```bash
# MWAA Logs
aws logs describe-log-groups --log-group-name-prefix airflow

# Task-specific logs via Airflow UI
```

## üîß Troubleshooting

### Problemas Comuns

#### Conex√£o Oracle
```bash
# Testar conectividade
telnet your-oracle-endpoint.amazonaws.com 1521

# Verificar security groups
aws ec2 describe-security-groups --group-ids sg-xxxxx
```

#### Performance Lenta
```sql
-- Criar √≠ndices Oracle
CREATE INDEX idx_table_updated_at ON schema.table(updated_at);

-- Ajustar warehouse Snowflake
ALTER WAREHOUSE COMPUTE_WH SET WAREHOUSE_SIZE = 'LARGE';
```

Ver [Guia Completo de Troubleshooting](docs/TROUBLESHOOTING_GUIDE.md)

## üìÅ Estrutura do Projeto

```
oracle-snowflake-pipeline/
‚îú‚îÄ‚îÄ dags/                      # DAGs Airflow
‚îÇ   ‚îú‚îÄ‚îÄ oracle_to_snowflake_dag.py
‚îÇ   ‚îú‚îÄ‚îÄ oracle_extractor.py
‚îÇ   ‚îî‚îÄ‚îÄ snowflake_loader.py
‚îú‚îÄ‚îÄ deployment/                # Scripts deploy
‚îú‚îÄ‚îÄ docs/                      # Documenta√ß√£o
‚îú‚îÄ‚îÄ tests/                     # Testes
‚îî‚îÄ‚îÄ sql/                       # Scripts SQL
```

## üß™ Testes

### Executar Testes
```bash
# Testes unit√°rios
python -m pytest tests/unit/

# Testes integra√ß√£o
python -m pytest tests/integration/

# Coverage
python -m pytest --cov=dags tests/
```

### Valida√ß√£o de Deploy
```bash
# Executar checklist
./scripts/validate_environment.py

# Testar conex√µes
python tests/integration/test_connections.py
```

## üîÑ Atualiza√ß√µes

### Adicionar Nova Tabela
1. Editar `SCHEMAS_CONFIG` no DAG
2. Commit e push para atualizar MWAA
3. Testar extra√ß√£o manualmente

### Modificar Schedule
```python
# No DAG principal
schedule_interval='0 */6 * * *'  # A cada 6 horas
```

## üìà Performance

### Otimiza√ß√µes Implementadas
- **Extra√ß√£o Incremental**: Apenas dados novos/modificados
- **Formato Parquet**: Compress√£o e performance
- **Pools de Conex√£o**: Controle de paralelismo
- **Staging S3**: Decoupling entre Oracle e Snowflake
- **Auto-scaling**: Warehouse Snowflake se ajusta automaticamente

### Benchmarks T√≠picos
- **Small datasets** (< 1M rows): 15-30 min
- **Medium datasets** (1-10M rows): 30-90 min  
- **Large datasets** (> 10M rows): 1-3 hours

## ü§ù Contribui√ß√£o

1. Fork o projeto
2. Crie feature branch (`git checkout -b feature/nova-funcionalidade`)
3. Commit mudan√ßas (`git commit -am 'Adiciona nova funcionalidade'`)
4. Push branch (`git push origin feature/nova-funcionalidade`)
5. Abra Pull Request

### Guidelines
- Seguir PEP 8 para Python
- Adicionar testes para novas funcionalidades
- Atualizar documenta√ß√£o
- Usar conventional commits

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a MIT License - veja o arquivo [LICENSE](LICENSE) para detalhes.

## üìû Suporte

### Contatos
- **T√©cnico**: data-team@company.com
- **Infraestrutura**: infra-team@company.com

### Issues
Para reportar bugs ou solicitar features, use [GitHub Issues](https://github.com/seu-usuario/oracle-snowflake-pipeline/issues).

### Documenta√ß√£o Adicional
- [Deployment Checklist](docs/DEPLOYMENT_CHECKLIST.md)
- [Troubleshooting Guide](docs/TROUBLESHOOTING_GUIDE.md)
- [Architecture Documentation](docs/ARCHITECTURE.md)

---

**Desenvolvido com ‚ù§Ô∏è pela equipe de Data Engineering**